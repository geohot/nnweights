{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "np.set_printoptions(suppress=True)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "def preproc(X_train, y_train):\n",
    "    X = X_train\n",
    "    X = X.reshape(X.shape[0], X.shape[1] * X.shape[2]).astype(\"float32\")\n",
    "    #X = X/255\n",
    "    X = preprocessing.scale(X)\n",
    "    Y = np_utils.to_categorical(y_train, 10)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = preproc(X_train, y_train)\n",
    "Xt, Yt = preproc(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "init = 0.01\n",
    "W1 = np.random.uniform(size=(784, 256),low=-init, high=init).astype(np.float32)\n",
    "W2 = np.random.uniform(size=(256, 32), low=-init, high=init).astype(np.float32)\n",
    "W3 = np.random.uniform(size=(32, 256),low=-init, high=init).astype(np.float32)\n",
    "W4 = np.random.uniform(size=(256, 784), low=-init, high=init).astype(np.float32)\n",
    "\n",
    "B1 = np.random.uniform(size=(256),low=-init, high=init).astype(np.float32)\n",
    "B2 = np.random.uniform(size=(32),low=-init, high=init).astype(np.float32)\n",
    "B3 = np.random.uniform(size=(256),low=-init, high=init).astype(np.float32)\n",
    "B4 = np.random.uniform(size=(784),low=-init, high=init).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add biases?\n",
    "def update(y0):\n",
    "    global W1, W2, W3, W4\n",
    "    global B1, B2, B3, B4\n",
    "    \n",
    "    lr = 0.001\n",
    "    def dtanh(x):\n",
    "        # pass in tanh\n",
    "        return 1 - (x**2)\n",
    "    \n",
    "    # forward pass\n",
    "    y1 = np.tanh(np.dot(y0, W1) + B1)\n",
    "    y2 = np.tanh(np.dot(y1, W2) + B2)\n",
    "    y3 = np.tanh(np.dot(y2, W3) + B3)\n",
    "    y4 = np.dot(y3, W4) + B4\n",
    "\n",
    "    # squared error derivative, (target - computed)\n",
    "    e4 = 2*(y0-y4)\n",
    "    \n",
    "    # backward pass, these should be net_i but dtanh is haxx\n",
    "    e3 = np.dot(e4, W4.T) * dtanh(y3)\n",
    "    e2 = np.dot(e3, W3.T) * dtanh(y2)\n",
    "    e1 = np.dot(e2, W2.T) * dtanh(y1)\n",
    "    #e0 = np.dot(e1, W1.T) * y0\n",
    "    \n",
    "    # update the weights\n",
    "    W4 += np.outer(y3, e4) * lr\n",
    "    W3 += np.outer(y2, e3) * lr\n",
    "    W2 += np.outer(y1, e2) * lr\n",
    "    W1 += np.outer(y0, e1) * lr\n",
    "    \n",
    "    # update the biases\n",
    "    B4 += e4 * lr\n",
    "    B3 += e3 * lr\n",
    "    B2 += e2 * lr\n",
    "    B1 += e1 * lr\n",
    "\n",
    "    return np.mean((y0-y4)**2)\n",
    "\n",
    "# run an epoch\n",
    "err = []\n",
    "for i in range(X.shape[0]):\n",
    "    err.append(update(X[i]))\n",
    "    if np.isnan(err[-1]):\n",
    "        print \"FAILED AT\",i, err[-10:]\n",
    "        break\n",
    "    if i % 1000 == 999:\n",
    "        print \"%4d: %f\" % (i+1, np.mean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
